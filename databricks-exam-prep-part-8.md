Hey Folks! Do you want to prepare yourself for the Databricks certification exam and don't know how to start? We are already in part 8 of our preparation for the Databricks Data Engineer Associate exam!

Did you know that Delta can OPTIMIZE the target file size of physical files in our tables to reduce file system I/O and network I/O? This is how Delta fixes small file problems!
This is something that you need to know if you want to prepare yourself for the Databricks certification exam! 

The post is part of Section 3 (Incremental Data Processing) of the exam outline and covers these topics of the Databricks Exam Guide:

● Identify who has written previous versions of a table.   
● Review a history of table transactions.   
● Roll back a table to a previous version.   
● Identify that a table can be rolled back to a previous version.   
● Query a specific version of a table.   
● Identify why Zordering is beneficial to Delta Lake tables.  
● Identify the kind of files Optimize compacts.     
● Identify a scenario in which MERGE should be used.   
● Identify MERGE as a command to deduplicate data upon writing.   
● Describe the benefits of the MERGE command.   
● Identify why a COPY INTO statement is not duplicating data in the target table.   
● Identify a scenario in which COPY INTO should be used.   
● Use COPY INTO to insert data.  

So, let's crush this exam! 

![](https://github.com/STEFANOVIVAS/databricks-data-engineer-exam-prep/blob/main/databricks-certification-8.png)
